{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    },
    "language_info": {
      "name": "python",
      "version": "3.7.8",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "name": "21116007.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nSBikuuJdXGw"
      },
      "source": [
        "# EE603 Coding Assignment\n",
        "- Use python3\n",
        "- Submit your \"rendered\" ipynb, i.e., with outputs of codes (plots and printed values) visible below\n",
        "- Do not change the return variables, as the evaluation is done by test cases based on the variables specified. Only add your code at \"### WRITE YOUR CODE HERE\"\n",
        "- Use only numpy and librosa library for computing and signal processing, no other package allowed\n",
        "- If you are using your mobile phone, you can use colab.research.google.com for coding\n",
        "- Do not define multiple functions using same name. We will be using eval.py to auto evaluate your codes. Please check with sample test cases before submitting. We will share the evaluation test cases with you after the submission deadline.\n",
        "- While submitting this file, change file name from 'YourRollNo.ipynb' to your actual roll no (Eg. 18204279.ipynb)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "trusted": true,
        "id": "wnQT8244dXG4"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import librosa\n",
        "from sklearn import metrics\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from pydub import AudioSegment\n",
        "from pydub.utils import make_chunks\n",
        "from scipy.io.wavfile import read\n",
        "import os\n",
        "import wave\n",
        "from matplotlib import pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fU3wXYwJdXG7"
      },
      "source": [
        "from glob import glob \n",
        "def readDir(dirname, Fs = 16000):\n",
        "    \n",
        "    '''\n",
        "    Each audio clip should be upto 10s long; split larger audio files into many clips (non-overlapping) \n",
        "\n",
        "    Use load_audio(file) \n",
        "    \n",
        "    Inputs: \n",
        "        dirname: (str) directory name\n",
        "        Fs: (int) sampling rate\n",
        "    Output: \n",
        "        x: np arrays of shape (Nclips, Nsamples) Nsamples correspond to 10s length. Use zero-padding for shorter clips.\n",
        "    '''  \n",
        "\n",
        "\n",
        "    ### WRITE YOUR CODE HERE - 5 MARKS\n",
        "    path = \"/content/music_wavs\"\n",
        "    files = os.listdir(path)\n",
        "    zero = []\n",
        "    for filename in glob.glob(os.path.join(path, '*.wav')):\n",
        "        samplerate, data = wavfile.read(filename)\n",
        "        zero.append(data)\n",
        "    myaudio = AudioSegment.from_file(\"filename\" , \"wav\") \n",
        "    chunk_length_ms = 10000 \n",
        "    zero_padding = len(myaudio) % chunk_length_ms\n",
        "    if (zero_padding != 0):\n",
        "        silence = AudioSegment.silent(duration=chunk_length_ms-zero_padding)\n",
        "        padded = myaudio + silence  \n",
        "        padded.export('padded_file.wav', format='wav')\n",
        "\n",
        "    audio = AudioSegment.from_file(\"padded_file.wav\" , \"wav\") \n",
        "    chunks = make_chunks(audio, chunk_length_ms)\n",
        "    for i, chunk in enumerate(chunks):\n",
        "        chunk_name = \"chunk{0}.wav\".format(i)\n",
        "        chunk.export(chunk_name, format=\"wav\")\n",
        "\n",
        "    u = int(len(audio)/10000)\n",
        "    no_of_files = u-1\n",
        "    file_name = []\n",
        "\n",
        "    for i in range(0, no_of_files):\n",
        "        file_name.append(\"chunk{0}.wav\".format(i))\n",
        "        x = read(file_name[i]) \n",
        "        x = np.array(a[1],dtype=float)\n",
        "\n",
        "    \n",
        "    return x "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "d9AsR_BDdXG9"
      },
      "source": [
        "def load_audio(filename, Fs = 16000):\n",
        "    '''\n",
        "    Inputs: \n",
        "        filename: (str) filename\n",
        "        Fs: (int) sampling rate\n",
        "    Output: \n",
        "        x: 1D np array \n",
        "    '''\n",
        "    \n",
        "\n",
        "    ### WRITE YOUR CODE HERE - 2 MARKS\n",
        "    x, Fs = librosa.load(filename)\n",
        "    \n",
        "    return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "CJK9E36ydXG-"
      },
      "source": [
        "def splitData(X, t, testFraction=0.2, randomize = False):\n",
        "    \"\"\"\n",
        "    Split the data randomly into training and test sets\n",
        "    Use numpy functions only\n",
        "    Inputs:\n",
        "        X: (np array of len Nclips) input feature vectors\n",
        "        t: (np array of len Nclips) targets; one hot vectors\n",
        "        testFraction: (float) Nclips_test = testFraction * Nclips\n",
        "    Outputs:\n",
        "        X_train: training set\n",
        "        X_test: test set\n",
        "        t_train: training labels\n",
        "        t_test: test labels\n",
        "    \"\"\"\n",
        "\n",
        "\n",
        "    ### WRITE YOUR CODE HERE - 5 MARKS\n",
        "    \n",
        "    X_train, X_test, t_train, t_test = train_test_split(X, t, test_size=0.20, random_state=42)\n",
        "    return X_train, t_train, X_test, t_test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "BHDX3OtZdXG_"
      },
      "source": [
        "def audio2mfcc(x, n_mfcc = 20, Fs = 16000):\n",
        "    \n",
        "    '''\n",
        "    Compute Mel-frequency cepstral coefficients (MFCCs)\n",
        "    Inputs:\n",
        "        x: np array of shape (Nclips,)\n",
        "        Fs: (int) sampling rate\n",
        "        n_mfcc: (int) number of MFCC features\n",
        "    Output:\n",
        "        X: (np array) MFCC sequence\n",
        "    '''\n",
        "\n",
        "    ### WRITE YOUR CODE HERE - 3 MARKS\n",
        "    X = librosa.feature.mfcc(x = x, sr = 16000, n_mfcc = 20)\n",
        "    return X "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JHBCXbkFdXHB"
      },
      "source": [
        "class Classifier: \n",
        "    '''\n",
        "    Create a linear classifier to classify each frame\n",
        "    '''\n",
        "    def __init__():\n",
        "        self.W = X_train  # define model parameters here\n",
        "        self.X = t_train\n",
        "        self.Y = X_test\n",
        "        self.Z = t_test\n",
        "        \n",
        "    def train(self,x_train, y_train):\n",
        "        '''\n",
        "        Train the linear classifier\n",
        "        Inputs:\n",
        "            x_train: training set\n",
        "            y_train: training labels\n",
        "        Output:\n",
        "            None\n",
        "        '''\n",
        "\n",
        "        ### WRITE YOUR CODE HERE - 0 MARKS\n",
        "        x_train = self.W\n",
        "        y_train = self.X\n",
        "        \n",
        "        logreg = LogisticRegression()\n",
        "        logreg.fit(x_train,y_train)\n",
        "        return \n",
        "    \n",
        "  #  def save_model(self, save_path):\n",
        "        '''\n",
        "        Save the trained model on local disk\n",
        "        Input:\n",
        "            save_path: location at which model is to be saved\n",
        "        Output:\n",
        "            None\n",
        "        '''\n",
        "        \n",
        "        ### WRITE YOUR CODE HERE - 0 MARKS\n",
        "            \n",
        "     #   return\n",
        "    \n",
        "    #def load_model(self, load_path):\n",
        "        '''\n",
        "        Save the trained model on local disk\n",
        "        Input:\n",
        "            load_path: location from which model is to be loaded\n",
        "        Output:\n",
        "            None\n",
        "        '''\n",
        "        \n",
        "        ### WRITE YOUR CODE HERE - 0 MARKS\n",
        "            \n",
        "     #   return\n",
        "\n",
        "\n",
        "    \n",
        "    def predict_framewise(self,x_test):\n",
        "        '''\n",
        "        Framewise classification (speech or music)\n",
        "        Input:\n",
        "            x_test: test set\n",
        "        Output:\n",
        "            y_pred_framewise = framewise prediction\n",
        "        '''\n",
        "        \n",
        "\n",
        "        ### WRITE YOUR CODE HERE - 5 MARKS\n",
        "\n",
        "        x_test = np.concatenate((self.Y, self.Z))\n",
        "        y_pred_framewise = logreg.predict(x_test)\n",
        "        \n",
        "        return y_pred_framewise \n",
        "    \n",
        "    def predict_aggregate(self,y_pred_framewise):\n",
        "        '''\n",
        "        Aggregate frames to give a single class label (music or speech) to the entire audio file\n",
        "        Input:\n",
        "            y_pred_framewise = framewise prediction\n",
        "        Output:\n",
        "            y_hat = frame aggregate (one-hot vectors)\n",
        "        '''\n",
        "\n",
        "        ### WRITE YOUR CODE HERE - 5 MARKS\n",
        "\n",
        "\n",
        "        return y_hat"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QNifGuV5dXHD"
      },
      "source": [
        "def computeCM(y, y_hat):\n",
        "    '''\n",
        "    Compute confusion matrix to evaluate your model\n",
        "    Inputs:\n",
        "        y = labels \n",
        "        y_hat = predicted output\n",
        "    Output:\n",
        "        confusion matrix: confusion matrix\n",
        "    '''\n",
        "\n",
        "    ### WRITE YOUR CODE HERE - 5 MARKS\n",
        "    \n",
        "    cnf_matrix = metrics.confusion_matrix(y, y_hat)\n",
        "    return cnf_matrix "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 346
        },
        "id": "KYAeCiKbdXHF",
        "outputId": "c075b4e6-8b41-41b8-f4b1-f34b74bee846"
      },
      "source": [
        "if __name__==\"__main__\":\n",
        "    \n",
        "    # Read audio\n",
        "    x_music = readDir('music_wavs', 16000)    #change it as per your directory\n",
        "    x_speech = readDir('speech_wavs', 16000)  #change it as per your directory\n",
        "    X = np.concatenate((x_music, x_speech))\n",
        "    \n",
        "    # Create labels\n",
        "    y_music = np.array([[1,0]]*len(x_music))\n",
        "    y_speech = np.array([[0,1]]*len(x_speech))\n",
        "    Y = np.concatenate((y_music, y_speech))\n",
        "    \n",
        "    \n",
        "    X_train, y_train, X_test, y_test = splitData(X, Y)\n",
        "    \n",
        "    # TRAINING \n",
        "    x_train = audio2mfcc(X_train, Fs)    # x_train: (Nclips, N_mfcc, N_frames)\n",
        "    model = Classifier() \n",
        "    model.train(x_train, y_train)        # y_train: (Nclips, 2) -repeat it N_frames times inside the train\n",
        "    \n",
        "    # TESTING \n",
        "    x_test = audio2mfcc(X_test, Fs) \n",
        "    y_pred = model.predict_framewise(x_test)   # y_predict: (Nclips, 2, N_frames)\n",
        "    y_hat = model.predict_aggregate(y_pred)    # y_hat: (Nclips, 2)\n",
        "    \n",
        "   # EVALUATION METRICS \n",
        "    confusion_matrix = computeCM(y_test, y_hat) \n",
        "    print(confusion_matrix) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-71-0b552b71c26f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;31m# Read audio\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mx_music\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreadDir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'music_wavs'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m16000\u001b[0m\u001b[0;34m)\u001b[0m    \u001b[0;31m#change it as per your directory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mx_speech\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreadDir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'speech_wavs'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m16000\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m#change it as per your directory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_music\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_speech\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-65-c7b5e3e6149c>\u001b[0m in \u001b[0;36mreadDir\u001b[0;34m(dirname, Fs)\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mfiles\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mzero\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'*.wav'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m         \u001b[0msamplerate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwavfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mzero\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'function' object has no attribute 'glob'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cdFlXtR647E1"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}